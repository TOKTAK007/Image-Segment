{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMoiYNndMnAvIXsPii0Qsh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TOKTAK007/Image-Segment/blob/main/Lotteryrev10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "rIebUL2IpdWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc7d5b1-ef97-487e-c384-c6d51ea92678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[812519 157196 845093 375805 121789]\n",
            "[157196 845093 375805 121789 913106]\n",
            "[845093 375805 121789 913106 613106]\n",
            "[375805 121789 913106 613106 484669]\n",
            "[121789 913106 613106 484669 943703]\n",
            "[913106 613106 484669 943703 929332]\n",
            "[613106 484669 943703 929332 331583]\n",
            "[484669 943703 929332 331583 436594]\n",
            "[943703 929332 331583 436594 620405]\n",
            "[929332 331583 436594 620405 981417]\n",
            "[331583 436594 620405 981417 361807]\n",
            "[436594 620405 981417 361807 319196]\n",
            "[620405 981417 361807 319196 155012]\n",
            "[981417 361807 319196 155012 658642]\n",
            "[361807 319196 155012 658642 395919]\n",
            "[319196 155012 658642 395919 970618]\n",
            "[155012 658642 395919 970618 737867]\n",
            "[658642 395919 970618 737867  61905]\n",
            "[395919 970618 737867  61905  98597]\n",
            "[970618 737867  61905  98597 944308]\n",
            "[737867  61905  98597 944308 880159]\n",
            "[ 61905  98597 944308 880159 819068]\n",
            "[ 98597 944308 880159 819068 639235]\n",
            "[944308 880159 819068 639235  77258]\n",
            "[880159 819068 639235  77258  32761]\n",
            "[819068 639235  77258  32761  45037]\n",
            "[639235  77258  32761  45037 386372]\n",
            "[ 77258  32761  45037 386372 578171]\n",
            "[ 32761  45037 386372 578171  70935]\n",
            "[ 45037 386372 578171  70935 114475]\n",
            "[386372 578171  70935 114475  46750]\n",
            "[578171  70935 114475  46750 910261]\n",
            "[ 70935 114475  46750 910261 556725]\n",
            "[114475  46750 910261 556725 713517]\n",
            "[ 46750 910261 556725 713517 691861]\n",
            "[910261 556725 713517 691861 292972]\n",
            "[556725 713517 691861 292972 684579]\n",
            "[713517 691861 292972 684579 501272]\n",
            "[691861 292972 684579 501272 100787]\n",
            "[292972 684579 501272 100787 472270]\n",
            "[684579 501272 100787 472270 890422]\n",
            "[501272 100787 472270 890422 835538]\n",
            "[100787 472270 890422 835538 424603]\n",
            "[472270 890422 835538 424603 912307]\n",
            "[890422 835538 424603 912307  38495]\n",
            "[835538 424603 912307  38495 803628]\n",
            "[424603 912307  38495 803628 201303]\n",
            "[912307  38495 803628 201303 100994]\n",
            "[ 38495 803628 201303 100994 972661]\n",
            "[803628 201303 100994 972661 506404]\n",
            "[201303 100994 972661 506404 286051]\n",
            "[100994 972661 506404 286051 837893]\n",
            "[972661 506404 286051 837893 244083]\n",
            "[506404 286051 837893 244083 999997]\n",
            "[286051 837893 244083 999997 945811]\n",
            "[837893 244083 999997 945811 569391]\n",
            "[244083 999997 945811 569391 873286]\n",
            "[999997 945811 569391 873286 347258]\n",
            "[945811 569391 873286 347258 516967]\n",
            "[569391 873286 347258 516967 831567]\n",
            "[873286 347258 516967 831567  51095]\n",
            "[347258 516967 831567  51095 503446]\n",
            "[516967 831567  51095 503446 875938]\n",
            "[831567  51095 503446 875938 781403]\n",
            "[ 51095 503446 875938 781403 589227]\n",
            "[503446 875938 781403 589227 491774]\n",
            "[875938 781403 589227 491774 510541]\n",
            "[781403 589227 491774 510541 529924]\n",
            "[589227 491774 510541 529924 453522]\n",
            "[491774 510541 529924 453522  17223]\n",
            "[510541 529924 453522  17223 967375]\n",
            "[529924 453522  17223 967375 812564]\n",
            "[453522  17223 967375 812564 691197]\n",
            "[ 17223 967375 812564 691197 340388]\n",
            "[967375 812564 691197 340388 798787]\n",
            "[812564 691197 340388 798787 775476]\n",
            "[691197 340388 798787 775476 387006]\n",
            "[340388 798787 775476 387006 369765]\n",
            "[798787 775476 387006 369765 943647]\n",
            "[775476 387006 369765 943647 174055]\n",
            "[387006 369765 943647 174055 516461]\n",
            "[369765 943647 174055 516461 962526]\n",
            "[943647 174055 516461 962526  61324]\n",
            "[174055 516461 962526  61324 570331]\n",
            "[516461 962526  61324 570331 109767]\n",
            "[962526  61324 570331 109767 724628]\n",
            "[ 61324 570331 109767 724628 345650]\n",
            "[570331 109767 724628 345650  74824]\n",
            "[109767 724628 345650  74824 967134]\n",
            "[724628 345650  74824 967134 197079]\n",
            "[345650  74824 967134 197079 735867]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "data = np.array([\n",
        "    812519, 157196, 845093, 375805, 121789, 913106,\n",
        "    613106, 484669, 943703, 929332, 331583, 436594,\n",
        "    620405, 981417, 361807, 319196, 155012, 658642,\n",
        "    395919, 970618, 737867, 61905, 98597, 944308,\n",
        "    880159, 819068, 639235, 77258, 32761, 45037,\n",
        "    386372, 578171, 70935, 114475, 46750, 910261,\n",
        "    556725, 713517, 691861, 292972, 684579, 501272,\n",
        "    100787, 472270, 890422, 835538, 424603, 912307,\n",
        "    38495, 803628, 201303, 100994, 972661, 506404,\n",
        "    286051, 837893, 244083, 999997, 945811, 569391,\n",
        "    873286, 347258, 516967, 831567, 51095, 503446,\n",
        "    875938, 781403, 589227, 491774, 510541, 529924,\n",
        "    453522, 17223, 967375, 812564, 691197, 340388,\n",
        "    798787, 775476, 387006, 369765, 943647, 174055,\n",
        "    516461, 962526, 61324, 570331, 109767, 724628,\n",
        "    345650, 74824, 967134, 197079, 735867, 356564\n",
        "])\n",
        "\n",
        "# set input and output sequence length\n",
        "seq_len = 5\n",
        "\n",
        "# create input sequences\n",
        "input_seqs = []\n",
        "for i in range(len(data)-seq_len):\n",
        "    input_seq = data[i:i+seq_len]\n",
        "    input_seqs.append(input_seq)\n",
        "\n",
        "for seq in input_seqs:\n",
        "    print(seq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "input_seq = data[i:i+seq_len] หมายถึงการสร้างชุดข้อมูล input โดยเริ่มจากข้อมูลที่ตำแหน่ง i ไปจนถึงตำแหน่ง i+seq_len-1 ซึ่ง seq_len คือความยาวของชุดข้อมูล input ที่ต้องการสร้าง เพื่อใช้ในการฝึกโมเดล LSTM โดยที่จะใช้ชุดข้อมูลนี้เป็นข้อมูล input สำหรับโมเดล LSTM แต่ละตัว ตัวอย่างเช่น ถ้า seq_len=5 และข้อมูลตัวอย่างคือ [1,2,3,4,5,6,7,8,9] จะได้ชุดข้อมูล input ดังนี้\n",
        "\n",
        "\n",
        "---\n",
        "[1,2,3,4,5]\n",
        "\n",
        "[2,3,4,5,6]\n",
        "\n",
        "[3,4,5,6,7]\n",
        "\n",
        "[4,5,6,7,8]\n",
        "\n",
        "[5,6,7,8,9]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NbyUtvvmsm_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create output sequences\n",
        "output_seqs = data[seq_len:]\n",
        "print(output_seqs[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVNxZmhhpxLo",
        "outputId": "60abbf46-4013-4adf-fe25-5ecfed1a3307"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[913106 613106 484669 943703 929332 331583 436594 620405 981417 361807]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# convert input_seqs and output_seqs to numpy arrays\n",
        "input_seqs = np.array(input_seqs)\n",
        "output_seqs = np.array(output_seqs)\n",
        "\n",
        "# convert numpy arrays to PyTorch tensors\n",
        "input_seqs = torch.from_numpy(input_seqs).float()\n",
        "output_seqs = torch.from_numpy(output_seqs).float()\n",
        "\n",
        "# reshape input_seqs to match expected input shape of LSTM (batch_size, seq_len, input_size)\n",
        "input_seqs = input_seqs.reshape(-1, seq_len, 1)\n",
        "\n",
        "# print shapes of input_seqs and output_seqs\n",
        "print(\"input_seqs shape:\", input_seqs.shape)\n",
        "print(\"output_seqs shape:\", output_seqs.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWwy9WQRt_Cv",
        "outputId": "3c5165fd-2370-45b5-a104-65d51ff20ea2"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_seqs shape: torch.Size([91, 5, 1])\n",
            "output_seqs shape: torch.Size([91])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_seqs[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maPZBaojDYFQ",
        "outputId": "429036fc-3c66-4071-cdd2-8a9c89091240"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[812519.],\n",
            "         [157196.],\n",
            "         [845093.],\n",
            "         [375805.],\n",
            "         [121789.]],\n",
            "\n",
            "        [[157196.],\n",
            "         [845093.],\n",
            "         [375805.],\n",
            "         [121789.],\n",
            "         [913106.]],\n",
            "\n",
            "        [[845093.],\n",
            "         [375805.],\n",
            "         [121789.],\n",
            "         [913106.],\n",
            "         [613106.]],\n",
            "\n",
            "        [[375805.],\n",
            "         [121789.],\n",
            "         [913106.],\n",
            "         [613106.],\n",
            "         [484669.]],\n",
            "\n",
            "        [[121789.],\n",
            "         [913106.],\n",
            "         [613106.],\n",
            "         [484669.],\n",
            "         [943703.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_seqs[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhQLMvMEE14d",
        "outputId": "4fd70e25-c016-4c99-f182-1e9a905fca5a"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([913106., 613106., 484669., 943703., 929332.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        ".reshape() เป็น method ของ numpy array ที่ใช้สำหรับเปลี่ยนรูปแบบของ array โดยจะระบุขนาดของ array ใหม่ด้วย โดยการใช้ -1 แทนขนาดที่ไม่ต้องการระบุ ในที่นี้ input_seqs มีขนาด (num_seqs, seq_len) แต่ LSTM ของ PyTorch ต้องการข้อมูลในรูปแบบ (num_seqs, seq_len, input_dim) \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "โดย input_dim คือจำนวน feature ของแต่ละ time step ใน input sequence ในที่นี้เป็น 1 เพราะ input sequence มีแค่ค่าเดียวในแต่ละ time step จึงจำเป็นต้องใช้ .reshape() เพื่อเปลี่ยนรูปแบบของ input_seqs ให้เป็น (num_seqs, seq_len, 1) โดยใช้ -1 แทน num_seqs และ 1 ในการระบุขนาดใหม่ของ input_seqs\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iXVZasx9vbg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#สร้างโมเดล LSTM\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):     #LSTM ของ PyTorch ต้องการข้อมูลในรูปแบบ (num_seqs, seq_len, input_dim)\n",
        "    super(LSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, 1)       #โดยมีจำนวน input features เป็น hidden_size และจำนวน output features เป็น 1 \n",
        "                                              #โดยค่่า output ที่ออกมาจะมีค่าเป็น (batch_size, 1)\n",
        "  def forward(self, x):\n",
        "      h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "      c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "      out, _= self.lstm(x, (h0, c0))          # __ แทน h0 และ c0 ที่เก็บไว้ใช้ในการคำนวณต่อไป  #output tensor ขนาด (sequence_length, batch_size, hidden_size)\n",
        "      out = self.fc(out[:, -1, :])\n",
        "      return out"
      ],
      "metadata": {
        "id": "Qc-MjIErLpw0"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#กำหนด parameter\n",
        "input_size = 1\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1000\n",
        "\n",
        "#สร้างโมเดล LSTM\n",
        "model = LSTM(input_size, hidden_size, num_layers)"
      ],
      "metadata": {
        "id": "HfmLwrvEsp2i"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "h0 ได้ถูกต้องต้องระบุขนาด dimension แรกของ Tensor h0 ให้เท่ากับ num_layers และขนาด dimension ที่สองของ Tensor h0 ให้เท่ากับ x.size(0) ซึ่งเป็นจำนวนตัวอย่างในชุดข้อมูลนั้น\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xy1B8tkBRy4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "out = self.fc(out[:, -1, :])\n",
        "จากนั้น out จะถูกส่งต่อไปยังชั้น Linear ด้วยเมท็อด fc ซึ่งเป็นชั้นเสริมเพื่อปรับขนาดของ tensor จาก (batch_size, hidden_size) เป็น (batch_size, 1) โดยการคูณกับเมทริกซ์เส้นเดียว (vector) ขนาด hidden_size ด้วยหลักการของหน่วยประมวลผลเชิงเส้น (linear transformation) ซึ่งในที่นี้คือการคูณกับเมทริกซ์ W ของชั้น Linear แล้วเทียบผลรวมกับเวกเตอร์ b ของชั้น Linear ด้วยการบวกเพื่อสร้าง output tensor ขนาด (batch_size, 1)\n",
        "\n",
        "\n",
        "---\n",
        "ดังนั้น เมื่อเราเลือกเอา output tensor จากโมเดล LSTM ใน time step สุดท้ายของแต่ละตัวอย่าง out[:, -1, :] จะเป็นการเลือกเฉพาะ dimension ที่สองของ tensor (dimension ที่เป็น batch_size) และ dimension ที่สามของ tensor (dimension ที่เป็น hidden_size) เพื่อให้ได้ tensor ขนาด (batch_size, hidden_size) ที่เก็บข้อมูล output ของโมเดล LSTM ใน time step สุดท้ายของแต่ละตัวอย่างในชุดข้อมูลเท่านั้น\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L-ED3gTGU55l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "การกำหนด batch_first=True หมายความว่าข้อมูลนำเข้าจะมีขนาดเป็น (batch_size, sequence_length, input_size) โดยที่ batch_size คือจำนวนตัวอย่างในแต่ละจุดเวลาและ \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "sequence_length คือความยาวของชุดข้อมูลในแต่ละตัวอย่าง ซึ่งใช้สำหรับการแบ่งชุดข้อมูลเป็นชุดเล็กๆ (minibatch) เพื่อให้การคำนวณในการฝึกแบบจำลอง LSTM สามารถทำได้เร็วขึ้นโดยใช้ GPU และให้ผลลัพธ์เป็น (batch_size, sequence_length, hidden_size) ซึ่งเป็นขนาดที่สามารถนำไปใช้ต่อได้ในชุดข้อมูลถัดไปของโมเดล LSTM\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ut1wVnfJNyTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#กำหนดค่า Loss และ Optimization\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "ynR-MIUWLq-q"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Model\n",
        "for epoch in range(num_epochs):\n",
        "  X = input_seqs\n",
        "  Y = output_seqs\n",
        "  inputs = X\n",
        "  targets = Y\n",
        "\n",
        "  #เริ่มต้นการฝึก Model\n",
        "  optimizer.zero_grad()\n",
        "  Y_pred = model(inputs)\n",
        "\n",
        "  #Cal Loss\n",
        "  loss = criterion(Y_pred, Y)\n",
        "\n",
        "  #คำนวณ gradient และอัปเดต weights\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if (epoch+1) % 100 == 0:\n",
        "        print('Epoch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5xsnyvrLq63",
        "outputId": "86cdc64b-a50c-4dbe-8f9d-ba2cc24732a6"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Train Loss: 377586155520.0000\n",
            "Epoch [200/1000], Train Loss: 377578356736.0000\n",
            "Epoch [300/1000], Train Loss: 377570951168.0000\n",
            "Epoch [400/1000], Train Loss: 377563742208.0000\n",
            "Epoch [500/1000], Train Loss: 377556598784.0000\n",
            "Epoch [600/1000], Train Loss: 377549553664.0000\n",
            "Epoch [700/1000], Train Loss: 377542508544.0000\n",
            "Epoch [800/1000], Train Loss: 377535496192.0000\n",
            "Epoch [900/1000], Train Loss: 377528483840.0000\n",
            "Epoch [1000/1000], Train Loss: 377521471488.0000\n"
          ]
        }
      ]
    }
  ]
}